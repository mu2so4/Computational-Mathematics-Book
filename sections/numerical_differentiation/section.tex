\documentclass[../main.tex]{subfile}

\begin{document}

\section{Численное дифференцирование}
Как и интегрирование, дифференцирование функции тоже далеко не всегда можно
провести аналитическими методами, например, если функция задана таблично. Также
формулы численного дифференцирования используются для решения дифференциальных
уравнений.

\subsection{Разностные операторы}
\begin{define}\label{eq:difference_operator}
	\textbf{Разностный оператор} $\Lambda_h[y(x)]$ с $k$-ым порядком
	аппроксимации \textbf{аппроксимирует} дифференциальный оператор
	$F[y(x)]$, если для всех достаточно гладких функций $y(x)$ выполняется
	условие
	\[\big|\Lambda_h[y(x)]-F[y(x)]\big|\le O(h^k),\]
	и при этом для некоторых $y(x)$ достигается равенство.
\end{define}

\begin{define}
	Разность $\Lambda_h[y(x)]-F[y(x)]$ называется \textbf{погрешностью}
	разностного оператора.
\end{define}

\begin{define}
	\textbf{Главный член ошибки} или \textbf{невязки} -- моном погрешности
	$\Delta_h[y(x)]$ такой, что
	\[\Lambda_h[y(x)]-F[y(x)]+O(h^k)=\Delta_h[y(x)]+O(h^{k+1}).\]
\end{define}

\begin{define} \label{eq:simplest_difference_operators}
	Определим простейщие разностные операторы 1-го порядка:
	\[\Lambda_h^+[y(x)]=\frac{y(x+h)-y(x)}{h},\qquad
	\Lambda_h^-[y(x)]=\frac{y(x)-y(x-h)}{h}.\]
\end{define}
\newpage

\begin{lemma}
	Данные разностные операторы аппроксимируют первую производную для всяких
	$y(x)\in C^3$ с первым порядком аппроксимации.
\end{lemma}

\begin{proof}
	Для определённости рассмотрим $\Lambda_h^+[y(x)]$; для \\
	$\Lambda_h^-[y(x)]$ доказательство аналогичное. Разложим функцию
	$y(x+h)$ в ряд Тейлора по $h$ при $h=0$ с точностью до $h^3$:
	\[f(x+h)=y(x)+hy'(x)+\frac{h^2}{2}y''(x)+\frac{h^3}{6}y'''(x)
	+O(h^4).\]
	Тогда
	\[\Lambda_h^+[y(x)]=y'(x)+\frac{h}{2}y''(x)+\frac{h^2}{6}
	y'''(x)+O(h^3),\]
	\[\Lambda_h[y(x)]-F[y(x)]=\frac{h}{2}y''(x)+\frac
	{h^2}{6}y'''(x)+O(h^3)\Rightarrow \Delta_h[y(x)]=\frac{h}{2}y''(x).\]
\end{proof}

\begin{define}
	Разностные операторы из \eqref{eq:simplest_difference_operators}
	относятся к \textbf{операторам направленной разности} (вперёд и назад
	соответственно). Из них можно составить оператор \textbf{симметричной}
	разности:
	\[\Lambda_h^*[y(x)]=\frac{\Lambda_h^+[y(x)]+\Lambda_h^-[y(x)]}{2}=
	\frac{y(x+h)-y(x-h)}{2h}.\]
\end{define}

\begin{lemma}
	Данный разностный оператор аппроксимирует первую производную для всяких
	$y(x)\in C^5$ со вторым порядком аппроксимации.
\end{lemma}

\begin{proof}
	Воспользовавшись разложением
	\[y(x\pm h)=y(x)\pm hy'(x)+\frac{h^2}{2!}y''(x)\pm\frac{h^3}{3!}y'''(x)+
	\frac{h^4}{4!}y^{(4)}(x)\pm\frac{h^5}{5!}y^{(5)}(x)+O(h^6),\]
	получим, что
	\[\Lambda_h^*[y(x)]=y'(x)+\frac{h^2}{6}y'''(x)+\frac{h^4}{120}y^{(5)}(x)
	+O(h^5).\]
\end{proof}

\begin{remark}
	Повышение порядка аппроксимации требует повышение гладкости
	аппроксимируемой функции.
\end{remark}

\subsubsection{Разностный оператор в общем виде}
Здесь мы рассмотрим общую задачу аппроксимации производных разностными
операторами.

\begin{define}\label{eq:general_difference_operator}
	Разностный оператор, аппроксимирующий производную $y^{(n)}(x)$, в общем
	виде имеет запись
	\[\boxed{\Lambda_h[y(x)]=\frac{1}{h^n}\sum_{j\in M}a_jy(x+jh)},\]
	где $M$ -- некоторое конечное множество чисел -- \underline{шаблон
	оператора}, -- а \\ $\{a_j\mid j\in M\}$ -- \underline{множество констант}.
\end{define}

\begin{theorem}[разностный оператор в общем виде]
\label{eq:general_difference_operator_theorem}
	Если для функции $y(x)$, шаблона оператора $M$, а также для множества
	констант $\{a_j\mid j\in M\}$ выполняются следующие условия:
	\begin{enumerate}[noitemsep]
		\item $y(x)\in C^{n+k+1}$,
		\item $\forall m\in\overline{0,n-1}\cup\overline{n+1,n+k-1}
			\quad\mathlarger\sum_{j\in M}a_jj^m=0$, считая при этом
			$0^0=1$,
		\item $\mathlarger\sum_{j\in M}a_jj^n=n!$,
		\item $\mathlarger\sum_{j\in M}a_jj^{n+k}\ne 0$,
	\end{enumerate}
	то разностный оператор \eqref{eq:general_difference_operator}
	аппроксимирует производную $y^{(n)}(x)$ с $k$-ым порядком аппроксимации,
	а его главный член невязки имеет вид
	\[\boxed{\Delta_h[y(x)]=\frac{h^k}{(n+k)!}\Big(\sum_{j\in M}a_jj^{n+k}\Big)
	y^{(n+k)}(x)}.\]
\end{theorem}

\begin{proof}
	Разложим в ряд Тейлора функцию:
	\[y(x+jh)=\sum_{m=0}^{n+k}\frac{(jh)^m}{m!}y^{(m)}(x)+O(h^{n+k+1}).\]

	Подставим это в $\Lambda_h[y(x)]$ и поменяем порядок суммирования:
	\[\Lambda_h[y(x)]=\frac{1}{h^n}\sum_{j\in M}a_j\sum_{m=0}^{n+k}\Big(
	\frac{(jh)^m}{m!}y^{(m)}(x)+O(h^{n+k+1})\Big)=\]
	\[=\sum_{m=0}^{n+k}\Big(\frac{h^{m-n}}{m!}y^{(m)}(x)\sum_{j\in M}
	a_jj^m\Big)+O(h^{k+1})=y^{(m)}(x)+\Delta_h[y(x)]+O(h^{k+1}).\]
\end{proof}

\begin{corollary}
	Если в предыдущей теореме известно, что
	\begin{enumerate}[nosep]
		\item $|M|<n+k$, то задача построения разностного оператора чаще
			всего (см. контрпример \eqref{eq:central_do_example})
			не имеет решения.
		\item $|M|=n+k$, то задача построения разностного оператора
			 имеет единственное решение.
		\item $|M|>n+k$, то задача построения разностного оператора
			образует $(|M|-n-k)$-параметрическое семейство.
	\end{enumerate}
\end{corollary}

\begin{example}
	Построим разностный оператор $n=1$ производной и с $k=2$ порядком
	аппроксимации на шаблоне $M=\{0,1,2\}$. Составим систему уравнений:
	\begin{equation*}
		\begin{cases}
			a_0+a_1+a_2=0, \\
			0+a_1+2a_2=1, \\
			0+a_1+4a_2=0. \\
		\end{cases}
		\Rightarrow
		\begin{cases}
			a_0 = -\frac{3}{2}, \\
			a_1 = 2, \\
			a_2 = -\frac{1}{2}. \\
		\end{cases}
	\end{equation*}

	Тогда желаемый разностный оператор имеет вид
	\[\Lambda_h[y(x)]=\frac{-3y(x)+4y(x+h)-y(x+2h)}{2h}.\]

	Найдём его главный член ошибки:
	\[\Delta_h[y(x)]=\frac{h^2}{3!}\big(0^3a_0+1^3a_1+2^3a_2\big)y'''(x)=
	-\frac{h^2}{3}y'''(x).\]
\end{example}
\newpage

\subsubsection{Симметричные разностные операторы}
Более внимательно рассмотрим симметричные операторы.

\begin{define}\label{eq:central_difference_operator}
	Разностный оператор \eqref{eq:general_difference_operator} является
	\textbf{симметричным}, если $\forall j\in M$ выполняется
	$a_j=(-1)^na_{-j}$, где $n$ -- порядок производной, чья аппроксимация
	ищется.
\end{define}

Из этого определения следует, что шаблон оператора $M$ -- множество,
симметричное относительно нуля.

\begin{theorem}[симметричный разностный оператор в общем виде]
	Если для функции $y(x)$, шаблона оператора $M$, а также для множества
	констант $\{a_j\mid j\in M\}$ выполняются следующие условия:
	\begin{enumerate}[noitemsep]
		\item $y(x)\in C^{n+k+1}$,
		\item $k$ чётное,
		\item Если $n$ чётное, то $a_0+2\sum_{j\in M_+}a_j=\delta_{0n}$,
			где $M_+=\{j\in M\mid j>0\}$,
		\item	\begin{equation*}
				\sum_{j\in M_+}a_jj^m=
				\begin{cases}
					0, m\in \{l\in\overline{1,n+k-2}\mid l
						\text{ и }n\text{ одной
						чётности}\}\backslash\{n\}; \\
					\frac{n!}{2}, m=n; \\
					\text{не } 0, m=n+k.
				\end{cases}
			\end{equation*}
	\end{enumerate}
	то симметричный разностный оператор
	\eqref{eq:central_difference_operator} аппроксимирует производную
	$y^{(n)}(x)$ с $k$-ым порядком аппроксимации, а главный член ошибки
	имеет вид
	\[\Delta_h[y(x)]=\frac{2h^k}{(n+k)!}\Big(\sum_{j\in M_+}a_jj^{n+k}\Big)
	y^{(n+k)}(x).\]
\end{theorem}

\begin{proof}
	Из определения следует, что сумма $\mathlarger\sum_{j\in M}a_jj^m$ равна
	нулю при всяких $m$, не совпадающих по чётности с порядком производной
	$n$. Также отсюда вытекает условие аппроксимировать производные с
	чётными порядками аппроксимации, потому что нечётный порядок всегда
	можно увеличить на единицу.

	В случае положительных $m$, совпадающих по чётности с $n$, выражение
	можно сократить в два раза, оставив, например, только положительные $j$.

	Условие 3 гарантирует равенство нулю суммы коэффициентов в случае чётной
	производной. В случае же нечётной производной, все парные коэффициенты
	сократят друг друга, а если $0\in M$, то $a_0=0$.
	
	Тогда мы можем  по теореме \eqref{eq:general_difference_operator_theorem}
	построить необходимый разностный оператор, главный член ошибки которой
	будет иметь заявленную форму независимо от чётности производной.
\end{proof}

\begin{example}\label{eq:central_do_example}
	Построим симметричный разностный оператор $n=2$ производной и с $k=4$
	порядком аппроксимации на шаблоне $M=\{-2,-1,0,1,2\}$.

	Можно подумать, что задача неразрешима, потому что $|M|<n+k$. Но
	уравнений в системе на самом деле не 6, а 3, потому что из них половина
	обращается в тождество из-за симметричности. Далее, число коэффициентов,
	которые мы ищем, тоже равно трём, поэтому система разрешима.

	Запишем и решим её:
	\begin{equation*}
		\begin{cases}
			a_0 + 2a_1 + 2a_2 = 0, \\
			a_1 + 4a_2 = 2, \\
			a_1 + 16a_2 = 0. \\
		\end{cases}
		\Rightarrow
		\begin{cases}
			a_0 = -5, \\
			a_1 = \frac{8}{3}, \\
			a_2 = -\frac{1}{6}.\\
		\end{cases}
	\end{equation*}

	Тогда разностный оператор имеет вид
	\[\Lambda_h[y(x)]=\frac{-y(x-2h)+16y(x-h)-30y(x)+16y(x+h)-y(x+2h)}
	{6h^2}.\]

	Теперь найдём его главный член ошибки:
	\[\Delta_h[y(x)]=\frac{2h^4}{6!}\big(0^6a_0+1^6a_1+2^6a_2\big)y^{(6)}
	(x)=-\frac{h^4}{45}y^{(6)}(x).\]
\end{example}
\newpage

\subsubsection{Разностный оператор $n$-й производной на минимальном равномерном
$(n+1)$-точечном шаблоне}

\begin{define}
	Шаблон оператора мощности $N+1$ называется \textbf{равномерным}, если \\
	$M=\{j_0+hk\mid k\in\overline{0,N}\}$, где $j_0$ -- некоторая константа,
	а $h$ -- шаг между точками шаблона.
\end{define}

\begin{define}
	\textbf{Оператор сдвига} $T_s$ -- оператор такой, что
	$\; T_s\circ y(x)=y(x+s)$.
\end{define}

\begin{lemma}
	Оператор сдвига $T_s$ является линейным.
\end{lemma}

\begin{proof}
	Очевидно.
\end{proof}

\begin{define}
	Введём следующие обозначения:
	\begin{itemize}[nosep]
		\item $T_0=E$.
		\item Если в контестке минимальный шаг сдвига равен $h$, то
			$T_{jh}=T_j$.
		\item Композиция операторов сдвига $T$: $\underset{j\text{ раз}}
			{\underbrace{T\circ T\circ...\circ T}}=T^j$.
		\item Общая запись разностного оператора на равномерном шаблоне:
			\[\Lambda_h[y(x)]=\frac{1}{h^n}\sum_{j=0}^{n}a_jy(x+jh)=
			\frac{1}{h^n}\Big(\sum_{j=0}^{n}T_{jh}\Big)\circ y(x)=
			\frac{1}{h^n}\underset{P_n(T)}{\underbrace{\Big(
			\sum_{j=0}^{n}T_j\Big)}}\circ y(x).\]
	\end{itemize}
\end{define}

\begin{theorem}
	Разностный оператор, аппроксимирующий $n$-ую производную на равномерном
	шаблоне, имеет вид
	\[\boxed{\Lambda_h[y(x)]=\frac{1}{h^n}\Big(\sum_{k=0}^{n}(-1)^kC_n^k\;
	T_{kh}\Big)\circ y(x)},\quad C_n^k=\frac{n!}{(n-k)!\;k!}.\]
\end{theorem}

\begin{proof}
	Рассмотрим разностный оператор, аппроксимирующий первую производную
	\[\Lambda_h^1[y(x)]=\Big(\frac{T_h-E}{h}\Big)\circ y(x)=\frac{y(x+h)-
	y(x)}{h}.\]
	Вторую производную мы найдём ''дифференцированием'' первой:
	\[\Lambda_h^2[y(x)]=\Big(\frac{T_h-E}{h}\Big)\circ\Lambda_h^1[y(x)]=
	\frac{1}{h^2}(T_h-E)^2\circ y(x).\]

	Аналогичным образом получаем, что
	\[\Lambda_h[y(x)]=\Lambda_h^n[y(x)]=\frac{1}{h^n}(T_h-E)^n\circ y(x).\]

	Зная, что $T^a\circ T^b=T^{a+b}$, разложим степень по биному Ньютона
	и получим требуемую форму.
\end{proof}

\begin{corollary}
	Симметричный разностный оператор, апппроксимирующий $y^{(n)}(x)$ на 
	равномерном $n+1$ шаблоне, имеет вид
	\[\boxed{\Lambda_h[y(x)]=\frac{1}{h^n}\Big(\sum_{k=0}^{n}(-1)^kC_n^k\;
	T_{kh}\Big)\circ T_{-\frac{nh}{2}}\circ y(x)},\quad C_n^k=\frac{n!}
	{(n-k)!\;k!}.\]
\end{corollary}

\subsection{Аппроксимация разностных схем дифференциальных уравнений}
Плавно приходим к тому, зачем это всё затевалось. А затевалось оно всё для
численного решения дифференциальных уравнений.

\begin{define}\label{eq:difference_scheme}
	\textbf{Разностная схема} разностого оператора $\Lambda_h[y]$
	\eqref{eq:difference_operator} -- это уравнение вида
	\[\Lambda_h[y]=0.\]
\end{define}

\begin{define}\label{eq:differential_equation_approximation}
	Разностная схема $\Lambda_h[y]=0$ аппроксимирует с $k$-м порядком
	дифференциальное уравнение $F[y]=0$ в смысле определения
	\eqref{eq:difference_operator}, если $\forall y(x)\in C^m$ верно
	$\big|\Lambda_h[y]\big|\le O(h^k)$, а для некоторых $y(x)$ достигается
	равенство.
\end{define}

\begin{theorem}[тривиальная]
	Если разностный оператор $\Lambda_h$ с $k$-м порядком аппроксимации
	аппроксимирует дифференциальный оператор $F[y]$, то разностная схема
	$\Lambda_h[y]=0$ аппроксимирует дифференциальное уравнение $F[y]=0$
	с порядком \underline{не ниже} $k$.
\end{theorem}

\begin{proof}
	Это напрямую следует из определения \eqref{eq:difference_operator}.
	Для этого достаточно подставить в него $F[y]=0$.

	Почему именно не ниже $k$? Потому что в условии может попасться
	такая функция $y(x)$, что по определению
	\eqref{eq:differential_equation_approximation} в неравенстве может быть
	достигнуто равенство. Но среди решений ДУ таких функций может и не быть,
	что и обеспечивает более высокую степень аппроксимации. См. пример
	\eqref{eq:differential_equation_shift_example}.
\end{proof}

И хотя эта теорема тривиальная, она очень важна, потому что позволяет создать
методы построения схем повышенной точности.

\begin{example}\label{eq:differential_equation_simplest_example}
	Необходимо решить обыкновенное дифференциальное уравнение
	\[y'(x)=g(x);\quad F[y]=y'(x)-g(x).\]

	Построим простейшую разностную схему, аппроксимирующую это уравнение.
	Воспользуемся для этого направленным вперёд разностным оператором
	первого порядка \eqref{eq:simplest_difference_operators}. Рассмотрим
	разностный оператор
	\[\Lambda_h[y(x)]=\frac{y(x+h)-y(x)}{h}-g(x).\]

	Исследуем, с каким порядком данный разностный оператор аппроксимирует
	дифференциальное уравнение. Разложим $y(x)$ в ряд Тейлора по $h$ при
	$h=0$:
	\[y(x+h)=y(x)+hy'(x)+\frac{h^2}{2}y''(x)+O(h^3).\]
	Здесь и далее будем писать $y$ и $g$ вместо $y(x)$ и $g(x)$
	соответственно. В этих обозначениях
	\[\Lambda_h[y]=y'+\frac{h}{2}y''-g+O(h^2),\]
	\[\Lambda_h[y]-F[y]=\underset{\Delta_h[y]}{\underbrace{\frac{h}{2}y''}}
	+O(h^2),\]
	получаем, что разностный оператор аппроксимирует дифференциальный
	оператор с первым порядком, если вторая производная $y$ отлична от нуля.
	В противном случае порядок аппроксимации будет выше. К тому же, если бы
	эта функция $y$ была линейной, то аппроксимация была бы точной.

	А вот так данная схема аппроксимиурует уравнение:
	\[\Lambda_h[y,g]-\underset{0}{\underbrace{F[y,g]}}=\Lambda_h[y,g]=
	\frac{h}{2}y''+O(h^2),\]
	то есть порядок аппроксимации уравнения совпал с порядком аппроксимации
	соответствующего оператора.
\end{example}

\begin{example}\label{eq:differential_equation_central_example}
	Решим то же уравнение, что и в прошлом примере
	\eqref{eq:differential_equation_simplest_example}, но теперь при помощи
	симметричной разностной схемы
	\[\Lambda_h[y]=\frac{f(x+h)-f(x-h)}{2h}-g(x).\]

	Как и тогда, разложим в ряд Тейлора:
	\[y(x\pm h)=y(x)\pm hy'(x)+\frac{h^2}{2}y''(x)\pm\frac{h^3}{6}y'''(x)+
	\frac{h^3}{6}y^{(4)}(x)+O(h^5).\]

	Подставив это, получим
	\[\Lambda_h=y'+\frac{h^2}{6}y'''+O(h^4)\quad\Rightarrow\quad
	\Lambda_h-F=\frac{h^2}{6}y'''+O(h^4),\]
	то есть и тут порядок аппроксимации оператора совпал с порядком
	аппроксимации уравнения.
\end{example}

\subsubsection{Повышение порядка разностных схем за счёт дифференциальных
следствий аппроксимируемого уравнения}

\begin{theorem}
	Если разностный оператор $\Lambda_h$ аппроксимирует дифференциальный
	оператор \eqref{eq:difference_operator} на каком-то шаблоне с $k$-ым
	порядком, то порядок аппроксимации оператора $T_{ch}\circ\Lambda_h$
	упадёт до первого порядка, а порядок аппроксимации соотвествующей
	схемы \eqref{eq:difference_scheme} сохранится.
\end{theorem}

\begin{proof}
	Рассмотрим разностный оператор $\Lambda_h[y(x)]=F[y(x)]$.
	Разложим в ряд Тейлора по $h$ при $h=0$:
	\[\Lambda_h[y(x)]=F[y(x)]+O(h^k).\]

	Подействуем оператором сдвига $T_{ch}$ и снова разложим в ряд Тейлора:
	\[T_{ch}\circ\Lambda_h[y(x)]=F[y(x+ch)]+O(h^k)=F[y(x)]+O(h).\]

	В разностной же схеме у нас $F[y]=0$, тогда
	\[T_{ch}\circ\Lambda_h[y(x)]=T_{ch}\circ\big(\cancel{F[y(x)]}+O(h^k)
	\big)=O(h^k).\]
\end{proof}

\begin{define}\label{eq:difference_consequence}
	Если известно, что $y(x)=g(x)$ на некотором отрезке и они достаточно
	гладкие ($\in C^n([a,b])$), то равенство $y^{(n)}(x)=g^{(n)}(x)$
	называется \textbf{дифференциальным следствием} $n$-го порядка.
\end{define}

\begin{example}\label{eq:differential_equation_shift_example}
	Решим уравнение из примера
	\eqref{eq:differential_equation_central_example} при помощи той же
	разностной схемы, но сдвинутой на $h$:
	\[\Lambda_h[y(x)]=\frac{y(x+2h)-y(x)}{2h}-g(x+h)=0.\]

	Разложим в ряд Тейлора $y(x+2h)$ и $g(x)$:
	\[y(x+2h)=y(x)+2hy'(x)+2h^2y''(x)+O(h^3),\]
	\[g(x+h)=g(x)+hg'(x)+O(h^2).\]

	Обозначив $y=y(x)$ и $g=g(x)$, получаем:
	\[\Lambda_h=y'+hy''+O(h^2)-g-hg'=
	(y'-g)+h(y''-g')+O(h^2).\]

	Если решение достаточно гладкое, то применимо дифференциальное
	следствие первого порядка:
	\[\Lambda_h[y]-F[y]=O(h^2).\]

	Таким образом, сдвиг ''испортил'' степень аппроксимации
	дифференциального оператора, но не схемы.
\end{example}
\newpage

\subsubsection{Компактные разностные схемы}
Идея компактных разностных схем -- использовать шаблон с максимальной
эффективностью, чтобы получить из него наибольшую степень аппроксимации. Для
этого помимо производных $y(x)$ аппроксимируют функцию $g(x)$.

\begin{define}
	\textbf{Компактная разностная схема} -- разностная схема
	$\Lambda_h[y,g]=0$, в которой содержатся аппроксимации производной
	$y^{(n)}(x)$ и функции $g(x)$ на одном и том же шаблоне. Компактная
	разностная схема записывается следующим образом:
	\[\Lambda_h\big[y(x),g(x)\big]=\overline{\Lambda}_h\big[y(x)\big]-
	\Omega_h\big[g(x)].\]
\end{define}

\begin{define}
	Введём следующие обозначения:
	\begin{enumerate}[nosep]
		\item $\Delta$ -- оператор, аппроксимирующий какую-то
			производную $y(x)$;
		\item $A$ -- оператор, аппроксимирующий функцию $g(x)$;
		\item $\Delta\circ y=A\circ g$ -- иная запись компактной
			разностной схемы;
		\item $\Delta_n^k$ и $A_n^k$ -- операторы, вместе
			аппроксимирующие $y^{(n)}(x)$ и $g(x)$ соответственно в
			разностной схеме $\Delta_n^k\circ y=A_n^k\circ g$
			с $k$-м порядком аппроксимации.
	\end{enumerate}
\end{define}

\begin{theorem}[о компактной разностной схеме]
\label{eq:compact_difference_scheme_theorem}
	Если компактная разностная схема $\Lambda_h[y(x),g(x)]$ аппроксимирует
	решение дифференциального уравнения $y^{(n)}-g=0$ на шаблоне $M$ с $k$-м
	порядком аппроксимации, разностный оператор $\overline{\Lambda}_h[y]$
	построен на коэффициентах $a_j$, а $\Omega_h\big[g(x)]$ -- на $b_j$, то
	для коэффициентов верно соотношение
	\[\boxed{\forall m\in\overline{0,k-1}\quad m!\sum_{j\in M}a_jj^{n+m}=
	(n+m)!\sum_{j\in M}b_jj^m}.\]
\end{theorem}

\begin{proof}
	Запишем разностные операторы через коэффициенты:
	\[\Lambda_h[y(x),g(x)]=\overline{\Lambda}_h[y(x)]-\Omega_h[g(x)]=0,\]
	\[\text{где }\overline{\Lambda}_h[y]=\frac{1}{h^n}\sum_{j\in M}a_j
	y(x+jh),\quad\Omega_h[g]=\sum_{j\in M}b_jg(x+jh).\]

	Распишем наше дифференциальное уравнение:
	\[y^{(n)}-g=\frac{1}{h^n}\sum_{j\in M}a_jy(x+jh)-\sum_{j\in M}b_j
	g(x+jh)+O(h^{k+1})=\]
	\[=\frac{1}{h^n}\sum_{j\in M}a_j\sum_{m=0}^{n+k} \frac{(jh)^m}{m!}
	y^{(m)}(x)-\sum_{j\in M}b_j\sum_{m=0}^{k}\frac{(jh)^m}{m!}g^{(m)}(x)+
	O(h^{k+1})=\]
	\[=\sum_{m=0}^{n+k}\frac{h^{m-n}}{m!}y^{(m)}(x)\sum_{j\in M}a_jj^m-
	\sum_{m=0}^{k}\frac{h^m}{m!}g^{(m)}\sum_{j\in M}b_jj^m+O(h^{k+1}).\]

	Tеорема \eqref{eq:general_difference_operator_theorem} позволяет
	установить следующие свойства коэффициентов $a_j$ и $b_j$:
	\begin{enumerate}[nosep]
		\item $\sum_{j\in M}a_jj^m=0,m\in\{0,...,n-1\}$,
		\item $\sum_{j\in M}a_jj^n=n!$,
		\item $\sum_{j\in M}b_j=1$.
	\end{enumerate}

	Тогда
	\[y^{(n)}-g=y^{(n)}+\sum_{m=n+1}^{n+k}\frac{h^{m-n}}{m!}y^{(m)}(x)
	\sum_{j\in M}a_jj^m-\]
	\[-g-\sum_{m=1}^{k}\frac{h^m}{m!}g^{(m)}\sum_{j\in M}b_jj^m+O(h^{k+1})=
	y^{(n)}-g+S+O(h^{k+1}).\]

	Обозначим $m-n=s\Rightarrow m=n+s$ и продолжим считать суммы $S$:
	\[S=\sum_{s=1}^{k}\frac{h^s}{(n+s)!}y^{(n+s)}\sum_{j\in M}a_jj^{n+s}-
	\sum_{m=1}^{k}\frac{h^m}{m!}g^{(m)}(x)\sum_{j\in M}b_jj^m.\]

	В первой сумме обозначим переменную цикла $s$ как $m$:
	\[S=\sum_{m=1}^{k}h^m\Big(\frac{1}{(n+m)!}y^{(n+m)}(x)\sum_{j\in M}a_j
	j^m-\frac{1}{m!}g^{(m)}(x)\sum_{j\in M}b_jj^m\Big).\]

	И наконец, применив дифференциальные следствия, получаем требуемые
	условия на коэффициенты.
\end{proof}

\begin{remark}
	Порядки аппроксимации разностных операторов $\overline{\Lambda}_h[y(x)]$
	и $\Omega_h[g(x)]$ не влияют на порядок аппроксимации компактной
	разностной схемы, хотя высокий порядок аппроксимации позволяет упростить
	систему уравнений из коэффициентов.
\end{remark}

\begin{remark}
	Чтобы задача построения компактной разностной схемы была разрешима,
	достаточно, чтобы
	\begin{itemize}[nosep]
		\item $|M|\ge n+1$,
		\item $2|M|\ge n+k+1$.
	\end{itemize}
\end{remark}

Однако мы не станем рассматривать примеры применения этой теоремы, так как она
слишком тяжеловесная.

\begin{example}
	Решим уравнение $y'(x)-g(x)=0$ на трёхточечном шаблоне $\{-1,0,1\}$ при
	помощи компактной разностной схемы и попробуем добиться $k=4$ степени
	аппроксимации. Аппроксимируем $g(x)$ по трём точкам на этом симметричном
	шаблоне и введём параметр $\alpha$:
	\[\Lambda_h=\frac{y(x+h)-y(x-h)}{2h}-\big(\alpha g(x-h)+(1-2\alpha)g(x)+
	\alpha g(x+h)\big).\]

	Теперь попробуем найти этот параметр, но сначала разложим всё в ряды
	Тейлора, а также обозначим $y=y(x)$ и $g=g(x)$:
	\[g(x\pm h)=g\pm hg'+\frac{h^2}{2}g''\pm\frac{h^3}{6}g'''+O(h^4),\]
	\[\Lambda_h=y'+\frac{h^2}{6}y'''-g-\alpha h^2g''+O(h^4)=
	(y'-g)+\Big(\frac{h^2}{6}y'''-\alpha h^2g''\Big).\]

	Воспользовавшись дифференциальным следствием первого порядка, получаем,
	что $\alpha=\frac{1}{6}$.
\end{example}
\newpage

\begin{example}\label{eq:compact_ds_example}
	Решим уравнение $y''(x)-g(x)=0$ на трёхточечном шаблоне $\{-1,0,1\}$
	при помощи компактной разностной схемы. Далее мы будем писать $y$ вместо
	$y(x)$ и $g$ вместо $g(x)$.

	Аппроксимируем вторую производную симметричным оператором (настоятельно
	рекомендую знать, как это делать, иначе сразу пересдача), а функцию
	$g$ -- по трём точкам, как в предыдущем примере:
	\[\Lambda_h[y,g]=\frac{y(x+h)-2y+y(x-h)}{h^2}-\big(\alpha g(x-h)+
	(1-2\alpha)g+\alpha g(x+h)\big).\]

	Разложим в ряд Тейлора по $h$ при $h=0$:
	\[y(x\pm h)=y\pm hy'+\frac{h^2}{2}y''\pm \frac{h^3}{6}y'''+\frac{h^4}
	{24}y^{(4)}\pm\frac{h^5}{120}y^{(5)}+O(h^6),\]
	тогда разностный оператор равен:
	\[\Lambda_h[y,g]=y''+\frac{h^2}{12}y^{(4)}-g-\alpha h^2g''+O(h^4)=
	(y''-g)+h^2\big(\frac{1}{12}y^{(4)}-\alpha g''\big)+O(h^4).\]

	Применив дифференциальное следствие 1-го порядка, получаем, что при
	$\alpha=\frac{1}{12}$ данное дифференциальное уравнение аппроксимируется
	с четвёртым порядком аппроксимации. Выразим соответствующий оператор $A$:
	\[\Omega_h[g]=\frac{1}{12}\big(g(x-h)+10g+g(x+h)\big)=
	\frac{(T_{-h}+10E+T_h)}{12}\circ g=A\circ g.\]
\end{example}

\subsubsection{Компактные разностные схемы, аппроксимирующие уравнения в частных
производных}
Компактные разностные схемы активно используются для решения уравнений в
частных производных.

\begin{define}
\label{eq:conservation_law}
	Если уравнение в частных производных имеет вид
	\[\frac{\partial^nu}{\partial t^n}=\frac{\partial^mf(u)}{\partial x^m},\]
	где $u=u(x,t)$, оно называется \textbf{законом сохранения}.
\end{define}

\begin{theorem}
	Если разностная схема аппроксимирует дифференциальное уравнение в
	частных производных \eqref{eq:conservation_law} на шаблоне $M$ с $k$-м
	порядком аппроксимации по $x$ и $t$, то её можно записать как
	\[\boxed{\widetilde{A}_n^k\circ\Delta_n^k\circ u=\widetilde{\Delta}_n^k
	\circ A_n^k\circ f},\]
	где пара операторов $\Delta_n^k$ и $A$ аппроксимируют с $k$-м порядком
	$n$-ую производную $u(x,t)$ по $t$, а $\widetilde\Delta_n^k$ и
	$\widetilde{A}$ -- $n$-ую производную $f(u)$ по $x$.
\end{theorem}

\begin{proof}
	Чтобы найти аппроксимацию частной производной $u$ по $t$ при помощи
	разностных схем, обозначим $g=\frac{\partial^mf}{\partial x^m}$,
	тогда уравнение примет вид
	\[u^{(n)}_t-g=0.\]

	На переменную $x$ пока не обращаем внимания. Построим компактную
	разностную схему:
	\[\Delta_n^k\circ u-A_n^k\circ g=0,\]
	\[\Delta_n^k=\sum_{j\in M}a_jT_{j\tau},\quad A_n^k=\sum_{j\in M}b_j
	T_{j\tau}.\]

	Подставим то, что мы спрятали за $g$, и воспользуемся линейностью
	оператора $A_n^k$:
	\[\Delta_n^k\circ u-A_n^k\circ \frac{\partial^mf}{\partial x^m}=
	\Delta_n^k\circ u-\frac{\partial^mA_n^kf}{\partial x^m}.\]

	Введём следующие обозначения:
	\[\varphi=A_n^k\circ f,\quad\psi=\Delta_n^k\circ u\]
	и получим следующую форму уравнения:
	\[\frac{\partial^m\varphi}{\partial x^m}=\psi.\]

	Мы получили дифференциальное уравнение относительно переменной $x$,
	относительно которой мы также можем построить компактную разностную
	схему, только уже по производной $f$. Совершим те же действия, что
	и в предыдущий раз. Обозначим операторы:
	\[\widetilde{\Delta}_n^k=\sum_{j\in M}a_jT_{jh},\quad
	\widetilde{A}_n^k=\sum_{j\in M}b_jT_{jh};\]
	таким образом, разностную схему можно записать как
	\[\widetilde{\Delta}_n^k\circ\varphi=\widetilde{A}_n^k\circ\psi.\]

	Коэффициенты данных операторов равны коэффициентам предыдущих,
	потому что обе пары операторов используют один и тот же шаблон $M$,
	а если коэффициенты $a_j$ при операторах $\Delta$ и $\widetilde{\Delta}$
	задать одинаково, то по теореме
	\eqref{eq:compact_difference_scheme_theorem} у операторов $A$ и
	$\widetilde{A}$ коэффициенты $b_j$ тоже совпадут.

	Наконец, подставим те выражения, которые мы обозначили как $\varphi$ и
	$\psi$, чтобы вернуться к исходным обозначениям:
	\[\widetilde{A}_n^k\circ\Delta_n^k\circ u=\widetilde{\Delta}_n^k\circ
	A_n^k\circ f.\]
\end{proof}

Рассмотрим простейший пример.

\begin{example}[параболическое уравнение]
	Найдём аппроксимацию дифференцильного уравнения
	\[\frac{\partial u}{\partial t}=\frac{\partial^2f(u)}{\partial x^2},\]
	называемого также как \textbf{параболическое уравнение}, с четвёртым
	порядком аппроксимации, на шаблоне $M=\{-1,1\}$. Запишем, чему равны
	соответствующие операторы (обратите внимание, что шаг времени $\tau$
	пишут верхним индексом, чтобы его не перепутать с $h$):
	\[\Delta=\frac{T^\tau-T^{-\tau}}{2\tau},\quad A=\frac{T^\tau+4E+
	T^{-\tau}}{6},\]
	\[\widetilde{\Delta}=\frac{T_h-2E+T_{-h}}{h^2},\quad
	\widetilde{A}=\frac{T_h+10E+T_{-h}}{12},\]
	и итоговая разностная схема имеет вид:
	\[\frac{T_h+10E+T_{-h}}{12}\circ\frac{T^\tau-T^{-\tau}}{2\tau}\circ f=
	\frac{T_h-2E+T_{-h}}{h^2}\circ\frac{T^\tau+4E+T^{-\tau}}{6}\circ u.\]
\end{example}
\newpage

\subsection{Сходимость разностных решений к решениям дифференциальных задач}
Это самое главное. Здесь мы будем исследовать сходимость уже не операторов
и схем, а конкретных разностных решений к истинным решениям дифференциальных
задач.

\begin{define}
	\textbf{Дифференциальная задача} -- задача, которая состоит в
	нахождении такого решения дифференциального уравнения, которое
	удовлетворяет некоторым начальным условиям. Задача Коши относится к
	таковым.
\end{define}

\begin{define}
	\textbf{Порядок сходимости разностного решения} $y_h(x)$ -- это число
	$k$ такое, что при точном решении $y(x)$ верно $y_h(x)=y(x)+O(h^k)$.
\end{define}

\begin{define}
	\textbf{Главный член ошибки} или \textbf{невязки разностного решения}
	-- моном $\Delta(h)$ такой, что $y_h(x)=y(x)+\delta_h(x)+O(h^{k+1})$.
\end{define}

Рассмотрим простейшую задачу Коши.

\begin{example}
\label{eq:simplest_difference_solution_example}
	Решим задачу Коши
	\[F[y(x)]=y'-y=0,\quad y(0)=1,\]
	чьё истинное решение равно $e^x$.

	Расмотрим разностную схему, которая аппроксимирует данное решение:
	\[\frac{y(x+h)-y(x)}{h}-y(x)=0.\]

	Теперь нужно внести туда начальное условие, но решать можно только
	на сетке. Введём разностную сетку
	\[x_j=jh,\;h=const\ll 1,\;j\in\mathbb N\cup\{0\}.\]

	Обозначим $y_j=y(x_j)=y(jh)$. Начальную аппроксимацию зададим точно:
	$y_0=y(0)=1$, и получим из разностной схемы рекуррентную и явную формулы
	членов последовательности $y_j$:
	\[\frac{y_{j+1}-y_j}{h}=y_j,\;y_0=y(0)=1\quad\Rightarrow\quad y_{j+1}=
	(1+h)y_j=(1+h)^{j+1}.\]

	Чего-то не хватает. Мы не можем связать точное решение разностной задачи
	с задачей дифференциальной. Если мы устемим $h$ к 0, то разностное
	решение устремится к единице. Чтобы первое сошлось ко второму, нужно
	записать её не через фиксированный узел $j$, а через фиксированные
	точки пространства:
	\[y=\frac{x_j}{j}\Rightarrow y_h(x_j)=(1+h)^\frac{x_j}{h}.\]

	Уберём индекс $j$ у $x$, он теперь ни на что не влияет. Теперь, если мы
	устремим $h$ к 0, то мы получим точное значение $y=e^x$.

	Проверим порядок сходимости данного разностного решения. Возьмём наше
	$y_h(x)$ и разложим его по $h$ при $h=0$. Однако это степенная функция
	с переменной $h$ и в основании, и в показателе. В этом нет ничего
	страшного, так как мы можем по основному логарифмическому тождеству
	занести основание степени в знаменатель:
	\[y_h(x)=(1+h)^\frac{x}{h}=e^{\frac{x}{h}\ln(1+h)}.\]

	Для разложения нам нужно вспомнить разложения логарифма и степени:
	\[e^x=1+x+\frac{x^2}{2!}+\frac{x^3}{3!}+O(x^4),\]
	\[\ln(1+h)=h-\frac{h^2}{2}+\frac{h^3}{3}-\frac{h^4}{4}+O(h^5).\]

	И тогда разностное решение разлагается следующим образом:
	\[\frac{x}{h}\ln(1+h)=\frac{x}{h}\big(h-\frac{h^2}{2}
	+O(h^3)\big)=x-\frac{xh}{2}+O(h^2),\]
	\[(1+h)^{x/h}=e^xe^{-\frac{xh}{2}+O(h^2)}=e^x\big(1-\frac{xh}{2}+
	O(h^2)\big)=e^x-\frac{h}{2}xe^x+O(h^2).\]

	Данное разностное решение сходится к точному с первым порядком
	аппроксимации. Главный член невязки
	\[\delta_h(x)=-\frac{h}{2}xe^x.\]
\end{example}

\begin{example}
\label{eq:central_difference_solution_example}
	Решим задачу Коши из примера
	\eqref{eq:simplest_difference_solution_example} при помощи следующей
	компактной разностной схемы
	\[\frac{y(x+h)-y(x)}{h}=\frac{y(x+h)+y(x)}{2}.\]

	Сдвинем её на $-h/2$, чтобы схема была симметричной:
	\[\frac{y(x+\frac{h}{2})-y(x-\frac{h}{2})}{h}=\frac{y(x+\frac{h}{2})+
	y(x-\frac{h}{2})}{2}.\]
	Запишем данную схему на сетке такой, что $y_0=1$:
	\[\frac{y_{j+1}-y_j}{h}=\frac{y_j+y_{j+1}}{2}\Rightarrow
	y_{j+1}=y_j\;\frac{2+h}{2-h}=\Big(\frac{1+h/2}{1-h/2}\Big)^{j+1}.\]

	Сделав замену $j=\frac{x}{h}$, окончательно получаем, что
	\[y_h(x)=\Big(\frac{1+h/2}{1-h/2}\Big)^{x/h}=e^x+\frac{h^2}{12}xe^x+
	O(h^4).\]

	Данное разностное решение имеет второй порядок точности. Вывод
	его главного члена ошибки -- упражнение.
\end{example}

Когда речь идёт об аппроксимации дифференциальных задач, то говорить нужно не
только об аппроксимации схемой аппроксимируемого уравнения, но и об
аппроксимации численно начальными и граничными условиями соответствующих
дифференциальных, и от порядка этой аппроксимации тоже может существенно
зависеть сходимость получаемого численного решения к точному.

\begin{example}\label{eq:spoiled_ds_example}
	Рассмотрим ещё раз пример
	\eqref{eq:central_difference_solution_example}, но пусть теперь
	начальное условие будет не точным, а с аппроксимацией с $n$-м
	порядком:
	\[y(x)=y_0=1+h^n,\quad n\ge 1.\]

	Проделаем тот же путь, что и в предыдущем примере, и получим
	\[y_{j+1}=y_j\;\frac{2+h}{2-h}=\Big(\frac{1+h/2}{1-h/2}\Big)
	^{j+1}(1+h^n).\]

	И окончательно
	\[y_h(x)=\big(e^x+\frac{h^2}{12}xe^x+O(h^4)\big)(1+h^n)=e^x+
	\frac{h^2}{12}xe^x+O(h^4)+h^ne^x+O(h^{2+n}).\]

	Если $n=1$, то мы испортим степень точности разностного решения.
	При $n=2$ мы получим
	\[e^x+h^2e^x\big(1+\frac{x}{12}\big)+O(h^4),\]
	то есть при $n>1$ порядок точности разностного решения не меняется.
\end{example}

\subsubsection{Составная разностная схема}
В некоторых случаях есть необходимость применения разностных схем разных
порядков. Например, тогда, когда у приграничных узлов более низкий порядок
аппроксимации.

\begin{theorem}
	Снижение на единицу порядка схемы в граничных и приграничных узлах
	разностной сетки (в отличие от снижения порядка аппроксимации самого
	граничного условия) не приводит к снижению порядка сходимости
	разностного решения. Большее снижение порядка схемы между тем уже
	снижает порядок аппроксимации разностного решения.
\end{theorem}

\noproof

\begin{example}
	Снова изменим разностную схему и начальные условия примера
	\eqref{eq:central_difference_solution_example}. $y_0$ возьмём точно.
	А вот $y_1$ и только его мы зададим иначе, а именно:
	\[\frac{y_1-y_0}{h}=y_0\Rightarrow y_1=(1+h)y_0,\]
	а следующие узлы мы зададим по-старому:
	\[y_{j+1}=y_j\;\frac{1+h/2}{1-h/2}=(1+h)\Big(\frac{1+h/2}{1-h/2}\Big)^j,
	\quad j\ge 1.\]

	И тогда в итоге
	\[y_h(x)=\Big(\frac{1+h/2}{1-h/2}\Big)^{\frac{x}{h}-1}
	(1+h)=e^x+\frac{h^2}{12}(x-6)xe^x+O(h^3).\]

	Схема сохранила второй порядок точности. Вывод главного члена ошибки --
	упражнение.
\end{example}

\subsubsection{Трёхточечные разностные схемы}
Двухточечные разностные схемы не годятся в случае, когда дифференциальное
уравнение второго порядка, потому что не хватает точек. Также дополнительная
точка, очевидно, позволяет повысить порядок аппроксимации разностного решения.

\begin{example}
	Применим к дифференциальному уравнению из примера
	\eqref{eq:simplest_difference_solution_example} трёхточечную
	разностную схему
	\[\frac{y(x+h)-y(x-h)}{2h}=y(x).\]

	Запишем уравнение на сетке:
	\[\frac{y_{j+1}-y_{j-1}}{2h}=y_j,\]
	что перейдёт в уравнение
	\[y_{j+1}-2hy_j-y_{j-1}=0.\]
	Изменим индексы:
	\[y_{j+2}-2hy_{j+1}-y_j=0.\]

	Требуются уже два начальных условия. Первое значение будет точным,
	а второе -- со вторым порядком аппроксимации:
	\[y_0=1,\quad y_1=1+h.\]

	Как решить это уравнение? Да, у нас есть рекуррентная формула, но очень
	хотелось бы получить явную. Поэтому будем искать решение в виде
	\[y_j=\lambda^j,\quad\lambda\ne 0,\]
	после чего уравнение примет вид
	\[\lambda^{j+2}-2h\lambda^{j+1}-\lambda^j=0\Rightarrow
	\lambda^2-2h\lambda-1=0.\]

	Получили характеристическое уравнение. Линейные дифференциальные
	уравнения с постоянными коэффициентами решаются подобным способом.
	Получаем, что
	\[\lambda=h\pm\sqrt{1+h^2}.\]

	Каждому из них соответствует своё частное решение:
	\[y_{j1}=\lambda_1^j=(h-\sqrt{1+h^2})^j,\]
	\[y_{j2}=\lambda_2^j=(h+\sqrt{1+h^2})^j,\]
	линейная комбинаций которых даёт общее решение
	\[y_j=C_1\lambda_1^j+C_2\lambda_2^j.\]

	Чтобы получить решение дифференциальной задачи, удовлетворяющее заданным
	начальным условиям, подставим их в систему уравнений:
	\[
	\begin{cases}
		C_1+C_2=1, \\
		C_1\lambda_1+C_2\lambda_2=1+h. \\
	\end{cases}
	\]

	Её решение -- упражнение.
\end{example}

\begin{example}
	Решим дифференциальное уравнение второго порядка
	\[y''+y=0\]
	с начальными условиями
	\[\;y(0)=0,\quad y'(0)=1.\]

	Нетрудно определить, что точное решение данной задачи Коши
	выглядит как $y=\sin x$. Общее же решение имеет вид
	\[y=C_1e^{-ix}+C_2e^{ix}.\]

	Запишем уравнение на сетке и сразу сформируем характеристическое
	уравнение:
	\[\frac{y_{j+1}-2y_j+y_{j-1}}{h^2}+y_j=0 \quad\Leftrightarrow\quad
	y_{j+2}+(2-h^2)y_{j+1}+y_j=0.\]

	Граничное условие $y_0=y(0)=0$ аппроксимируется точно. А вот из
	$y'(0)=1$ мы можем получить $y_1$ только с первым порядком
	аппроксимации, тут применение составной разностной схемы избежать не
	получится:
	\[\frac{y_1-y_0}{h}=1\Rightarrow y_1=h.\]

	Но эта схема аппроксимирует граничные условия с первым порядком! Если бы
	мы задали $y_1=1+h$, порядок аппроксимации разностного решения снизился
	бы до первого порядка.

	Составим характеристическое уравнение по $y_j=\lambda^j$:
	\[\lambda^2-(2-h^2)\lambda+1=0.\]

	Его решение:
	\[\lambda_1=a+ib,\quad\lambda_2=a-ib,\]
	\[\text{где } a=1-\frac{h^2}{2},\quad b=h\sqrt{1-\frac{h^2}{4}}.\]

	Решение уравнения в общем виде может быть представлено следующим образом:
	\[y_j=C_1\lambda_1^j+C_2\lambda_2^j.\]

	Чтобы было проще возводить число в степень, приведём его к
	тригонометрической форме:
	\[r^2=a^2+b^2=1,\quad\varphi=\arccos{\Big(1-\frac{h^2}{2}\Big)},\]
	и решения характеристического уравнения примут вид:
	\[\lambda_1^j=e^{ij\varphi}=\cos{\varphi j}+i\sin{\varphi j},\]
	\[\lambda_2^j=e^{-ij\varphi}=\cos{\varphi j}-i\sin{\varphi j}.\]

	Комплексное решение означает комплексные коэффициенты. А уравнение
	чисто действительное. Чтобы уйти от комплексных чисел, выразим
	частные решения следующим образом:
	\[\widetilde{y_j^1}=\frac{\lambda_1^j+\lambda_2^j}{2}=\cos{\varphi j},
	\quad\widetilde{y_j^2}=\frac{\lambda_1^j-\lambda_2^j}{2i}=
	\sin{\varphi j}.\]

	Теперь мы можем записать общее решение уравнения в общем виде:
	\[y_j=C_1\lambda_1^j+C_2\lambda_2^j=C_1\cos{\varphi j}+C_2
	\sin{\varphi j},\]
	а начальные условия дают следующее частное решение:
	\[y_j=\frac{h}{\sin\varphi}\sin{\varphi j}.\]

	Окончательно получаем разностное решение
	\[y_h(x)=\frac{h}{\sin\varphi}\sin{\frac{x}{h}\varphi}.\]

	Проверка его аппроксимации -- упражнение.
\end{example}

\subsection{Линейные разностные схемы с постоянными коэффициентами}
Чуть ранее мы рассмотрели более простые случаи подобных разностных схем. Теперь
мы выведем общий алгоритм разрешения разностных схем подобного типа.

\begin{define}\label{eq:linear_difference_scheme}
	\textbf{Линейная разностная схема с постоянными коэффициентами} --
	разностная схема $\Lambda[y(x)]=0$, где
	\[\Lambda[y(x)]=\sum_{m=0}^{n}a_my_{j+m},\quad a_m=const.\]
\end{define}

Решение линейных разностных схем очень похоже на решение линейных
дифференциальных уравнений с постоянными коэффициентами
\[F[y(x)]=\sum_{m=0}^{n}a_my^{(m)}(x)=0,\quad a_n\ne 0,\]
чьё общее решение равно
\[y=\sum_{m=1}^{l}\Big(e^{\lambda_mx}\cdot\sum_{j=0}^{s_m-1}C_{mj}x^j\Big),\]
где $l$ -- число различных корней соответствующего характеристического уравнения
\[P(\lambda)=\sum_{m=0}^{n}a_m\lambda^m=0,\]
$s_i$ -- кратность его $i$ корня, причём $\sum_{m=1}^{l}s_m=n$.

\subsubsection{Случай различных действительных корней}
\begin{theorem}
	Если у характеристического многочлена линейного разностного уравнения
	\eqref{eq:linear_difference_scheme} все корни различны, то его общее
	решение имеет вид
	\[\boxed{y_j=\sum_{m=1}^{n}C_m\lambda_m^j}.\]
\end{theorem}

\begin{proof}
	По аналогии с дифференциальными уравнениями, обозначим за $\lambda_i$
	корни (нули) соответствующего характеристического уравнения, причём
	$\lambda_i\ne 0\quad\forall i\in\overline{1,n}$.

	Поскольку $\lambda_i$ разные и действительные, положим, что решение
	имеет вид
	\[y_j=\sum_{m=1}^{n}C_m\lambda_m^j.\]
	Проверим его правильность, для этого мы подставим в схему $y_j$:
	\[\Lambda_h[y_j]=\sum_{m=0}^{n}a_m\lambda^ {j+m}=\lambda^j\sum_{m=0}^
	{n}a_m\lambda^m=0.\]

	Значит, разностное решение, найденное данным способом, найдено верно.
\end{proof}

\begin{example}\label{eq:4dot_difference_equation}
	Решим 4-точечное разностное уравнение
	\[y_{j+3}-2y_{j+2}-y_{j+1}+2y_j=0,\qquad y_0=0,\;y_1=1,\;y_2=3\]
	и найдём решение, удовлетворяющее граничным условиям.

	Соответствующее характеристическое уравнение $\lambda^3-2\lambda^2-
	\lambda+2=0$ имеет корни $\{-1,1,2\}$, тогда общее решение имеет вид:
	\[y_j=C_1(-1)^j+C_2+C_32^j.\]

	Найдём такое решение, которое удовлетворяет заданному начальному
	условию:
	\[
		\begin{cases}
			C_1+C_2+C_3=0, \\
			-C_1+C_2+2C_3=1, \\
			C_1+C_2+4C_3=3. \\
		\end{cases}
		\Rightarrow
		\begin{cases}
			C_1=0, \\
			C_2=-1, \\
			C_3=1. \\
		\end{cases}
	\]

	Полученное решение задачи Коши:
	\[y_j=2^j-1.\]
\end{example}

\subsubsection{Случай кратных корней}
\begin{lemma}\label{eq:polynomial_power_lowering}
	Если $\mu$ является нулём многочлена $P(x)$, то
	\[(T_1-\mu E)\circ\big(\mu^xP_k(x)\big)=\mu^{x+1}P_{k-1}(j).\]
\end{lemma}

\begin{proof}
	Представим полином как
	\[P_k(x)=\sum_{m=0}^{k}a_mx^m.\]

	Тогда мы сразу получаем
	\[(T_1-\mu E)\circ(\mu^xP_k(x))=\mu^{x+1}\cdot\big(P_k(x+1)-P_k(x)
	\big)=\]
	\[=\mu^{x+1}\sum_{m=0}^{k}a_m\big((x+1)^m-x^m\big)=\mu^{j+1}\sum_{m=1}^
	{k}a_mP_{m-1}(x)=\mu^{x+1}P_{k-1}(x).\]
\end{proof}

\begin{lemma}\label{eq:characteristic_nullicifation}
	Если $\mu$ -- корень кратности $s$ характеристического многочлена
	линейного разностного уравнения \eqref{eq:linear_difference_scheme},
	то $\forall k\in\overline{1,s-1}$ верно
	\[(T-\mu E)^s\circ y_j^k=0,\]
\end{lemma}

\begin{proof}
	Рассмотрим случай $k=s-1$ и применим лемму
	\eqref{eq:polynomial_power_lowering}:
	\[(T-\mu E)^{k+1}\circ(j^k\mu^j)=(T-\mu E)^k\circ\big(P_{k-1}(j)\mu^
	{j+1}\big)=...=\]
	\[=(T-\mu E)\circ(C\cdot\mu^{j+k})=C(\mu^{j+k+1}-\mu^{j+k+1})=0.\]

	При меньшем $k$ зануление произошло бы быстрее.
\end{proof}

\begin{theorem}\label{eq:repeated_characteristics}
	Если характеристический многочлен линейного разностного уравнения
	\eqref{eq:linear_difference_scheme} имеет $l$ различных корней $\mu_i$
	с кратностями $s_i$ соответственно, то общее решение имеет вид
	\[\boxed{y_j=\sum_{i=1}^{l}\big(\mu_i^j\cdot\sum_{m=0}^{s_i-1}C_{jm}j^m
	\big)}.\]
\end{theorem}

\begin{proof}
	Введём обозначения операторов сдвига:
	\[T_h\circ y=T\circ y_j=y_{j+1},\quad T^m\circ y_j=y_{j+m}.\]
	Запишем полимом разностной схемы через операторы:
	\[\Lambda[y_j]=P_n(T)\circ y_j, \text{ где } P_n(T)=\sum_{m=0}^{n}a_m
	T^m.\]

	Рассмотрим ноль характеристического уравнения $\mu_i$. Ввиду того, что
	$\mu_i$ является корнем данного многочлена кратности $s_i$, представим
	$P_n(T)$ как
	\[P_n(T)=(T-\mu_i E)^s\circ P_{n-s_i}(T)=P_{n-s_i}(T)\circ(T-\mu_i E)
	^s_i.\]

	Обозначим ту часть $y_j$, которая содержит $\mu_i$ как
	\[y_j^{\mu_i}=\sum_{m=0}^{s_i-1}C_{jm}j^m.\]

	Тогда по лемме \eqref{eq:characteristic_nullicifation}
	\[P_n(T)\circ y_j^{\mu_i}=P_{n-s_i}\circ\big((T-\mu_i E)^s\circ y_j^
	{\mu_i}\big)=0.\]

	С другими $\mu_i$ проделываем аналогичную операцию и получаем, что
	разностное уравнение мы решили правильно.
\end{proof}
\begin{example}
	Решим разностное уравнение
	\[y_{j+3}+7y_{j+2}-16y_{j+1}+12y_j=0.\]

	Корни характеристического уравнения:
	\[\lambda_1=\lambda_2=-2,\quad\lambda_3=-3.\]

	Общее решение:
	\[y_j=(jC_1+C_2)(-2)^j+(-3)^j.\]
\end{example}

\subsubsection{Случай комплексных корней}
Данный случай неприятен тем, что мы хотим такое решение, которое бы содержало
действительные, а не комплексные коэффициенты.

\begin{theorem}\label{eq:complex_roots_de}
	Если характеристический многочлен линейного разностного уравнения
	\eqref{eq:linear_difference_scheme} имеет комплексный корень
	$\mu=re^{i\varphi}$ кратности $s$, то та часть общего решения $y_j$,
	которая образована $\mu$, может иметь вид
	\[\boxed{y_j^\mu=\rho^j\sum_{k=0}^{s-1}j^k\big(C_{k1}\cos{j\varphi}+
	C_{k2}\sin{j\varphi}\big)}.\]
\end{theorem}

\begin{proof}
	Из теоремы \eqref{eq:repeated_characteristics}, мы можем получить
	$y_j^\mu$, не обращая на комплексность $\mu$. Так как $\mu$ -- ноль
	характеристического уравнения с действительными коэффициентами, то и
	$\overline{\mu}=\rho e^ {-j\varphi}$ тоже является его нулём, причём с
	той же кратностью $s$.

	Как и прежде, применим невырожденное линейное преобразование. Обозначим
	\[y_j^k=j^k\rho^je^{ij\varphi},\quad \overline{y}_j^k=j^k\rho^je^
	{-ij\varphi},\quad k\in\overline{0,s-1}.\]

	Сделаем следующие подстановки:
	\[\widetilde{y_j^k}=\frac{y_j^k+\overline{y_j^k}}{2}=j^k\rho^j\cos
	{j\varphi},\quad\widehat{y_j^k}=\frac{y_j^k-\overline{y_j^k}}{2i}=j^k
	\rho^j\sin{j\varphi}.\]

	Так как $\widetilde{y_j^k}=0$ и $\widehat{y_j^k}=0$, то такая
	подстановка корректна.
\end{proof}

\begin{example}\label{eq:complexes_difference_eq}
	Решим разностное уравнение
	\[y_{j+4}-4y_{j+3}+8y_{j+2}-8y_{j+1}+4y_j=0.\]

	Характеристический полином имеет вид
	\[P(\lambda)=(\lambda^2-2\lambda+2)^2=0.\]

	Получаем пару комплексно-сопряжённых корней каждый двойной кратности:
	\[\lambda_{1,2}=1\pm i.\]

	Представим $\lambda$ в комплексной форме:
	\[\rho=\sqrt{2},\quad\alpha=\pm\frac{\pi}{4}\quad\Rightarrow\quad
	\lambda=\sqrt{2}e^{\pm i\frac{\pi}{2}}.\]

	Окончательно, общее решение имеет вид
	\[y_j=\big(C_1j+C_2\big)\cos{\frac{\pi}{4}j}+\big(C_3j+C_4\big)
	\sin{\frac{\pi}{4}j}.\]
\end{example}

\subsection{Устойчивость разностных схем}
Далеко не все разностные схемы подходят для разностных уравнений. Почему?
Потому что может произойти такое, что разностная схема при определённых
условиях может не сойтись к точному решению конкретной дифференциальной
задачи.

Как таковую неустойчивую разностную схему получить довольно сложно (наши методы
к ним точно не приведут), но если очень постараться, то эта задача достижима.
Приведём пример Годунова.

\begin{example}
	Найдём разностное решение следующей задачи Коши:
	\[y'+y=0,\;y(0)=0.\]

	Очевидно, что точное решение $y=e^{-x}$.

	Для решения данной дифференциальной задачи можно использовать один из
	этих разностных операторов, обозначим их:
	\[A=\frac{y_{j+1}-y_{j-1}}{2h},\quad B=\frac{y_{j+1}-y_j}{h}.\]

	Из них Годунов смог сложить следующую разностную схему, которая является
	неустойчивой:
	\[4A-3B+y_j=0.\]

	Зададим начальные условия:
	\[y_0=1,\quad\frac{y_1-y_0}{h}=-y_0\Rightarrow y_1=1-h.\]

	Покажем, что разностная схема неустойчивая.
	Соответствующее разностное уравнение имеет вид
	\[y_{j+2}-(h+3)y_{j+1}+2=0.\]

	Корни характеристического уравнения:
	\[\lambda_1=\frac{3+h-\sqrt{h^2+6h+1}}{2}=1-h+O(h^2),\]
	\[\lambda_2=\frac{3+h+\sqrt{h^2+6h+1}}{2}=2+O(h),\]
	и, соответственно, общее решение
	\[y_j=C_1\lambda_1^j+C_2\lambda_2^j.\]

	Коэффициенты $C_1$ и $C_2$ такие, что удовлетворяют начальным условиям,
	берутся из системы уравнений
	\[
		\begin{cases}
			C_1+C_2=1, \\
			\lambda_1C_1+\lambda_2C_2=1-h. \\
		\end{cases}
	\]

	Коэффициенты приблизительно равны
	\[C_1=O(h^2),\quad C_2=1+O(h).\]

	Теперь мы рассмотрим каждое частное решение поподробней. То, что в своём
	составе имеет $\lambda_1$, является ''хорошим'', так как после
	преобразования в явную формулу мы получим $(1-h)^{x/h}$, что и даёт в
	пределе $e^{-x}$. Но решение при $\lambda_2$ всё портит: пусть оно и при
	$O(h^2)$, но корень имеет в своём составе двойку:
	\[\lambda_1^j=2^j\approx 2^{x/h},\quad C_2\lambda_2^j=2^{x/h}\cdot
	O(h^2),\]
	при стремлении $h$ к нулю мы получим, что предел данного частного
	решения стремится к бесконечности. Это и делает неустойчивым данное
	разностное решение.
\end{example}

\subsection{Численное решение нелинейных обыкновенных ДУ}
Всё, что мы делали до этого -- это решали на простейших примерах линейные
уравнения, исследовали аппроксимации, их сходимость и устойчивость, однако
помимо линейных уравнений есть также нелинейные уравнения, особенно те, что не
имеют аналитического решения.

В курсе дифференциальных уравнений как-то была доказана следующая важная
теорема:

\begin{theorem}[существования и единственности решения задачи Коши]
	Если в уравнении $y'=f(x,y)$ функция $f(x,y)$ и её частная производная
	$f'_y$ непрерывны в некоторой области $D$, содержащей точку $(x_0,
	y_0)$, то существует единственное решение $y=\varphi(x)$ этого
	уравнения, удовлетворяющее начальному условию $y(x_0)=y_0$.
\end{theorem}

В одномерном случае ($y\in \mathbb R$) мы её можем доказать при помощи
построения ломаных, что превращается в разностную схему. Простейший способ
данного типа называется схемой Эйлера.

\begin{define}
	\textbf{Схема Эйлера} дифференциального уравнения $y'=f(y)$ -- это
	разностная схема
	\[\frac{y_{j+1}-y_j}{h}=f(y_j)\Leftrightarrow y_{j+1}=y_j+hf(y_j),\]
	где
	\[y_j=y(x_j),\quad x_j=jh.\]
\end{define}

\subsubsection{Методы Рунге-Кутты}
К сожалению, схемой Эйлера можно аппроксимировать нелинейное ОДУ только с первым
порядком. Казалось бы: а почему бы не применить компактную разностную схему
\[\frac{y_{j+1}-y_j}{h}=\frac{f(y_{j+1})+f(y_j)}{2}?\]
Да, она аппроксимирует со вторым порядком, и всё бы ничего, если бы мы не были
вынуждены искать $y_j$ через нелинейное уравнение, чего делать не очень хочется.
Да, мы где-то в первой главе изучили численные методы решения подобных уравнений,
но это дополнительные вычислительные затраты для компьютеров. А нельзя ли
повысить порядок аппроксимации иными способами? Конечно же, можно.

\begin{define}
	\textbf{Схема Эйлера с пересчётом} дифференциального уравнения $y'=f(y)$
	-- это разностная схема
	\[\frac{y_{j+1}-y_j}{h}=f(y_{j+\frac{1}{2}}),\quad\text{где }
	y_{j+\frac{1}{2}}=y_j+\frac{h}{2}f(y_j).\]
\end{define}

\begin{theorem}
	Схема Эйлера с пересчётом имеет второй порядок аппроксимации.
\end{theorem}

\begin{proof}
	Введём разностную схему
	\[\Lambda_h[y]=\frac{y_{j+1}-y_j}{h}-f(y_{j+1/2})=0.\]

	При исследовании аппроксимаций нам следует перейти от дискретной схемы к
	схеме от непрерывной переменной:
	\[\Lambda_h[y(x)]=\frac{y(x+h)-y(x)}{h}-f\Big(y\big(x+\frac{h}{2}\big)
	\Big).\]

	Наконец, разложим в ряд Тейлора обе части схемы по $h$ при $h=0$:
	\[\Lambda_h[y(x)]=\cancel{y'}-\cancel{f(y)}+\frac{h}{2}\Big(y''-
	\underset{y''}{\underbrace{f'_y(y)y'}}\Big)+O(h^2)=O(h^2).\]
\end{proof}

Данная схема является разновидностью так называемых схем Рунге-Кутты. Их идея в
том, чтобы использовать аппроксимации без разрастания шаблона схемы, без
решения нелинейных уравнений и получения $y_j$ в явном виде.

\begin{define}
	\textbf{Метод Рунге-Кутты} в общем имеет представление
	\[y_j^1=f_1(h,y_j),\]
	\[y_j^2=f_2(h,y_j,y_j^1),\]
	\[...\]
	\[y_j^n=f_n(h,y_j,y_j^1,...,y_j^{n-1})=y_{j+1},\]
	где $y_j^i$ -- вспомогательные значения, а $f_i$ -- вспомогательные
	функции.
\end{define}

Техника построения таких схем индивидуальна и довольно сложна. Схемы высших
порядков определяются неоднозначно, получаемые схемы могут обладать разными
свойствами. Очень широко используется следующая трёхточечная схема Рунге-Кутты:

\begin{define}
	Одна из трёхточечных схем имеет вид
	\[y_j^1=y_j+hf(y_j),\]
	\[y_j^2=\frac{1}{4}\big(3y_j+y_j^1+hf(y_j^1)\big),\]
	\[y_{j+1}=\frac{1}{3}\big(y_j+2y_j^2+2hf(y_j^2)\big).\]
\end{define}

Доказательство третьего порядка аппроксимации данной схемы -- упражнение.

\subsubsection{Метод Рунге оценки точности численных решений}
Помимо теоретических методов поиска порядка аппроксимации схем используются и
эмпирические.

Следующий алгоритм используется в том случае, если нам известно точное или
квазиточное (то есть то, что считаем за точное) решение дифференциального
уравнения.

\begin{algorithm}
	Обозначим за $u(x)$ точное решение схемы, а за $v_h(x)$ -- разностное
	с порядком аппроксимации $k$. При сетке от 0 до $x=jh$ ошибка разностной
	схемы приблизительно равна
	\[\Delta v_h=v_h=v_h(x)-u(x)\approx Ch^k,\quad C\ne 0.\]

	Если же мы возьмем сетку с вдвое меньшим шагом, мы получим ошибку
	\[\Delta v_{h/2}=v_{h/2}(x)-u(x)\approx C\Big(\frac{h}{2}\Big)^k.\]

	Возьмём ошибки под модуль разделим первую на вторую:
	\[\Big|\frac{\Delta v_h}{\Delta v_{h/2}}\Big|\approx2^k\;\Rightarrow\;
	\boxed{k\approx\log_2{\Big|\frac{\Delta v_h}{\Delta v_{h/2}}\Big|}}.\]
\end{algorithm}

Порядок аппроксимации можно найти и без (квази)точного решения $u(x)$.

\begin{algorithm}
	Посчитаем приблизительно ошибки разностной схемы $v(x)$ на сетках с
	шагом $h$, $h/2$ и $h/4$:
	\[\Delta v_h=v_h(x)-u(x)\approx Ch^k,\quad C>0,\]
	\[\Delta v_{h/2}=v_{h/2}(x)-u(x)\approx C\Big(\frac{h}{2}\Big)^k,\]
	\[\Delta v_{h/4}=v_{h/4}(x)-u(x)\approx C\Big(\frac{h}{4}\Big)^k.\]

	Нужно устранить $u(x)$. Для этого мы вычтем первое из второго, второе
	из третьего, и полученные разности разделим:
	\[\Delta_1=v_h-v_{h/2}\approx Ch^k(1-2^{-k}),\]
	\[\Delta_2=v_{h/2}-v_{h/4}\approx C\Big(\frac{h}{2}\Big)^k(1-2^{-k}),\]
	\[\boxed{k\approx\log_2{\Big|\frac{\Delta_1}{\Delta_2}\Big|}}.\]

	Отсутствие точного решения не помешает оценить размер ошибки,
	которую можно выразить через $\Delta_1$:
	\[Ch^k\approx\frac{\Delta_1}{1-2^{-k}}\;\Rightarrow\; \boxed{\Delta v_h
	\approx\frac{\Delta_1}{1-\frac{|\Delta_2|}{|\Delta_1|}}}.\]
\end{algorithm}

\subsection{Уравнения в частных производных}
Уравнения в частных производных бывают эллиптическими и гиперболическими. Мы
рассмотрим только гиперболические, начнём с самого простого из них.

\begin{define}\label{eq:convection-diffusion_equation}
	\textbf{Линейное уравнение переноса} и задача Коши к нему имеет вид
	\[u_t+au_x=0,\quad t>0,\quad a=const>0,\quad u(x,0)=v(x)\in
	\mathbb C^1.\]
\end{define}

\begin{lemma}\label{eq:CDE_solution}
	Задача Коши к линейному уравнению переноса
	\eqref{eq:convection-diffusion_equation} имеет решение
	\[\boxed{u(x,t)=v(x-at)}.\]
\end{lemma}

\begin{proof}
	Найдём характеристику данного уравнения, то есть производную
	координаты по времени:
	\[\frac{dx}{dt}=a\Rightarrow x=at+x_0,\]
	где $x_0=const$, то есть характеристика -- это семейство прямых с
	заданным углом к положительному направлению оси $x$.

	Продифференцируем $u$ по $t$ полностью, опираясь на нашу характеристику:
	\[\frac{d}{dt}u(at+x_0,t)=u_t+au_x=0.\]

	Тогда получается, что $u=const$ на каждой отдельно взятой
	характеристике, то есть, для любой точки $(x,t)$ существует точка
	$(x_0,0)$ такая, что $u(x,t)=u(x_0,0)=v(x_0)$. Тогда $x_0=x-at$ и
	$u(x,t)=v(x-at)$.
\end{proof}

Почему линейное уравнение переноса имеет такое название? Потому что на графике
это выглядит так, будто мы осуществили параллельный перенос графика, причём
перенос с постоянной скоростью во всех точках: \\

\subfile{graph-CDE}

\subsubsection{Линейные гиперболические системы}
\begin{define}
	Скаляр $\lambda$ и ненулевой вектор $v$ называются собственным
	значением и собственным вектором матрицы $A$ соответственно, если для
	них выполняется равенство
	\[A\boldsymbol v=\lambda \boldsymbol v.\]
\end{define}

\begin{define}\label{eq:hyperbolic_system}
	Линейная система \[\boldsymbol u_t+A\boldsymbol u_x=0,\]
	где $\boldsymbol u\in \mathbb R^n$, называется
	\textbf{гиперболической}, если все собственные значения матрицы $A$
	действительные, а также существует базис пространства $\mathbb R^n$
	из её собственных векторов.
\end{define}

\begin{define}\label{eq:strict_hyperbolic_system}
	Гиперболическая система \eqref{eq:hyperbolic_system} является
	\textbf{строгой}, если все собственные значения матрицы $A$ различные.
\end{define}

В таком случае принято нумеровать собственные значения по порядку их
возрастания, то есть $\lambda_1<\lambda_2<...<\lambda_n$.

\begin{lemma}\label{eq:hyperbolic_invariant_form}
	Строгую линейную гиперболическую систему
	\eqref{eq:strict_hyperbolic_system} можно записать в виде
	\[\boxed{\boldsymbol\omega_t+\Lambda\boldsymbol\omega_x=0},\]
	где $\boldsymbol\omega=S\boldsymbol u$ -- вектор инвариантов, $S$ --
	матрица, чьи строки составлены из собственных векторов матрицы $A$,
	а $\Lambda$ -- диагональная матрица соответствующих им собственных
	значений.
\end{lemma}

\begin{proof}
	Пусть $\boldsymbol l^1,...,\boldsymbol l^n$ -- собственные векторы
	матрицы $A$, а $\lambda_1,...\lambda_n$ -- соответствующие им
	собственные значения. Пусть $S$ -- это матрица, чьи строки составлены из
	собственных векторов матрицы $A$, то есть $S=(\boldsymbol l^1,..,
	\boldsymbol l^n)^T$, а элементы диагональной матрицы $\Lambda$
	составлены из соответствующих собственных значений. Тогда очевидно, что
	\[SA=\Lambda S.\]

	Обозначим $\boldsymbol\omega=S\boldsymbol u=(\omega^1,...,\omega^n)^T$
	-- вектор инвариантов, где $\omega_i$ -- инвариант относительно $i$
	характеристики. Матрица $S$ невырожденная, так как собственные векторы
	линейно независимые, так что на неё можно домножить слева
	гиперболическую систему и немного её преобразовать:

	\[S\boldsymbol u_t+SA\boldsymbol u_x=S\boldsymbol u_t+A\Lambda
	\boldsymbol u_x=\boldsymbol\omega_t+\Lambda\boldsymbol\omega_x,\]
	и мы получили требуемую запись уравнения.
\end{proof}

\begin{theorem}[решения задачи Коши строгой линейной гиперболической системы]
	Решение системы \eqref{eq:strict_hyperbolic_system} с начальным условием
	$\boldsymbol u(x,0)=\boldsymbol{v}(x)$ имеет вид
	\[\boldsymbol u(x,t)=S^{-1}\boldsymbol\omega,\]
	где $S$ -- матрица, чьи строки составлены из собственных векторов
	матрицы $A$, $\boldsymbol\omega^i(x,t)=p_i(x-\lambda_i t)$,\quad $p(x)=
	\boldsymbol\omega(x,0)=S\boldsymbol v$, а $\lambda_i$ --
	соответствующие собственные значения этой матрицы.
\end{theorem}

\begin{proof}
	После преобразования строгой гиперболической системы, проведённого в
	лемме \eqref{eq:hyperbolic_invariant_form}, полученная квазилинейная
	гиперболическая система, которая распадается на $n$ независимых друг от
	друга линейных уравнений переноса относительно инвариантов вдоль своих
	характеристик. Каждое уравнение имеет вид
	\[(\omega^i)_t+\lambda_i(\omega^i)_x=0,\]
	то есть является линейным уравнением переноса. Начальное значение $v(x)$
	преобразовывается в
	\[\boldsymbol p(x)=\boldsymbol\omega(x,0)=S\boldsymbol v.\]

	По лемме \eqref{eq:CDE_solution}, решение такого уравнения переноса
	с данным начальным условием равно
	\[\omega^i(x,t)=p_i(x-\lambda_i t),\]
	и теперь, чтобы от $\boldsymbol\omega$ обратно перейти к
	$\boldsymbol u$, нужно домножить на $S^{-1}$:
	\[\boldsymbol u=S^{-1}\boldsymbol\omega.\]
\end{proof}

Графически решение гиперболического решения выглядит так: \\

\subfile{graph-hyperbolic_system_solution} \\

Читается этот график следующим образом. Точка $(x,t)$ является нашим начальным
условием. В неё необходимо привести все характеристики, которые
''распростраяняются'' по прямым. $\lambda_i$ становятся просто тангенсами
углов наклона этих самых прямых. При таких значениях мы получаем $x_1,...,x_n$
в качестве решения задачи Коши.

\begin{example}\label{eq:wave_equation_example}
	В качестве примера рассмотрим волновое уравнение
	\[u_{tt}=a^2u_{xx},\quad a=const\ne 0,\]
	которое нам известно с курса физики 4 семестра и эквивалентно
	системе
	\[\begin{cases}
		u_t+v_x=0, \\
		v_t+a^2u_x=0. \\
	\end{cases}\]

	Здесь
	\[\boldsymbol{u}=
		\begin{pmatrix}
			u \\
			v \\
		\end{pmatrix},
	\qquad
	A=
		\begin{pmatrix}
			0 & 1 \\
			a^2 & 0 \\
		\end{pmatrix}.
	\]

	Собственные значения и собственные вектора матрицы $A$ равны
	\[\lambda_1=-a,\quad \lambda_2=a,\qquad
	\boldsymbol{l}_1=(a,-1),\quad \boldsymbol{l}_2=(a,1),\]
	\[
		S=
		\begin{pmatrix}
			a & -1 \\
			a & 1  \\
		\end{pmatrix}.
	\]

	$|S|\ne 0$ при $a\ne 0$, так что исходная система гиперболическая.

	Вектор инвариантов $\boldsymbol{\omega}=S\boldsymbol{u}$ имеет
	компоненты
	\[\omega^1=au-v,\quad \omega^2=au+v,\]

	первая из которых сохраняется вдоль семейства характеристик
	$\lambda_1=-a\Rightarrow x+at=C$, а вторая -- вдоль семейства
	характеристик $\lambda_2=a\Rightarrow x-at=C$. \\

	\subfile{graph-wave_equation}
	
	В результате получаем, что
	\[\omega^1(x_0,t_0)=\omega^1(x_1,0)=p_1(x+at),\qquad
	  \omega^2(x_0,t_0)=\omega^2(x_2,0)=p_2(x-at),\]
	где $p_1,\;p_2\in \mathbb C^2$ -- функции, задающие начальные значения
	инвариантов.
	
	Общее решение исходной схемы, таким образом, равно
	\[u(x,t)=\frac{1}{2a}\big(\omega^2(x,t)+\omega^1(x,t)\big)=
	\frac{1}{2a}\big(p_2(x-at)+p_1(x+at)\big),\]
	\[v(x,t)=\frac{1}{2}\big(\omega^2(x,t)-\omega^1(x,t)\big)=
	\frac{1}{2}\big(p_2(x-at)-p_1(x+at)\big).\]
	
	Если же для этой системы поставить задачу Коши с начальными данными
	\[u(x,0)=u_0(x),\quad v(x,0)=v_0(x),\quad u,v\in\mathbb C^2,\]
	то её решение имеет вид
	\[u(x,t)=\frac{1}{2}\big(u_0(x-at)+u_0(x+at)\big)+
	\frac{1}{2a}\big(v_0(x-at)-v_0(x+at)\big),\]
	\[v(x,t)=\frac{1}{2}\Big(v_0(x-at)+v_0(x+at)+
	a\big(u_0(x-at)-u_0(x+at)\big)\Big).\]
\end{example}

\subsubsection{Начально-краевая задача для линейной гиперболической системы ДУ}

\begin{define}
	\textbf{Начально-краевая задача} -- задача о нахождении решения
	дифференциального уравнения такого, что оно удовлетворяет начальным
	и граничным условиям.
\end{define}

\begin{theorem}
	Пусть матрица $A$ из уравнения \eqref{eq:hyperbolic_system} имеет $n$
	различных собственных значений, из которых $k$ отрицательные, а $m$
	неположительные. Пронумеруем их в порядке возрастания:
	\[\lambda_1\le...\le\lambda_k<0=\lambda_{k+1}=...=\lambda_m<
	\lambda_{m+1}\le...\le\lambda_n\].

	Обозначим соответствующие собственные векторы как $\boldsymbol l_1,...,
	\boldsymbol l_n$,
	а компоненты вектора инвариантов из $\boldsymbol\omega=S\boldsymbol u$
	как $\omega_1,...,\omega_n$.

	Чтобы корректно задать краевую задачу, необходимо и достаточно, чтобы

	\begin{enumerate}[nosep]
		\item
			Количество граничных условий на левой границе совпадает с
			количеством положительных характеристик, а на правой --
			с количеством отрицательных, то есть
			\[
				\begin{cases}
					\big(\boldsymbol\varphi^i,
						\boldsymbol u(0,t)\big)=f_i(t),&
						i\in\overline{1,k}, \\
					\big(\boldsymbol\varphi^i,
						\boldsymbol u(X,t)\big)=f_i(t),&
						i\in\overline{m+1,n}, \\
				\end{cases}
			\]
			где $f_i(t)$ -- некоторые скалярные функции,
			$\boldsymbol\varphi^i$ -- некоторые константные векторы,
			а $(\boldsymbol a,\boldsymbol b)$ -- скалярное
			произведение векторов,
		\item
			На левой границе $x=0$ должно быть верно
			\[|\boldsymbol l^1,...,\boldsymbol l^m,
			\boldsymbol\varphi^{m+1},...,
			\boldsymbol\varphi^n|\ne 0,\]
			где $|\boldsymbol a_1,...,\boldsymbol a_k|$ --
			определитель матриц, чьи столбцы составлены из
			$k$-мерных векторов $\boldsymbol a_1,...,
			\boldsymbol a_k$,
		\item
			На правой границе $x=X$ должно быть верно
			\[|\boldsymbol\varphi^1,...,\boldsymbol\varphi^k,
			\boldsymbol l^{k+1},...,\boldsymbol l^n|\ne 0.\]
	\end{enumerate}
\end{theorem}

\begin{proof}
	На левую границу $x=0$ изнутри области приходит первые $k$
	характеристик. Нулевые характеристики можно провести к любой границе,
	то есть для них можно не задавать граничные условия. Остальные $n-m$
	условий мы определим в граничных условиях. Аналогично сделаем и с правой
	границей, там понадобится уже $n-k$ граничных условий.

	Также корректность краевой задачи означает, что вектор $\boldsymbol u$
	однозначно определяется на границах. необходимо, чтобы система уравнений
	была разрешима, что достижимо при ненулевом определителе матрицы.

	На левой границе будет
	\[
	\begin{cases}
		\big(\boldsymbol l^i,\boldsymbol u(0,t)
			\big)=\omega_i, &
			i\in\overline{1,m}, \\
		\big(\boldsymbol\varphi^i,
			\boldsymbol u(0,t)\big)=f_i(t),&
			i\in \overline{m+1,n}. \\
	\end{cases}
	\]

	На правой же границе будет
	\[
	\begin{cases}
		\big(\boldsymbol\varphi^i,
			\boldsymbol u(X,t)\big)=f_i(t),&
			i\in\overline{1,k}, \\
		\big(\boldsymbol l^i\boldsymbol u(X,t)
			\big)=\omega_i, &
			i\in\overline{k+1,n}, \\
	\end{cases}
	\]

	Чтобы системы были разрешимы, нужно, чтобы определители матриц были
	отличны от нуля, благодаря чему и получаем необходимые условия.
\end{proof}

\begin{example}
	Рассмотрим начально-краевую задачу на границе $[0,X]$ для линейного
	уравнения переноса \eqref{eq:convection-diffusion_equation}
	\[u_t+au_x=0.\]
	Характеристика у нас одна, и она положительна. Изобразим её возможные
	положения: \\

	\subfile{graph-CDE_boundary_problem} \\

	Очевидно, что для корректной постановки начально-краевой задачи
	начальное условие необходимо пускать от правой границы $X$, то есть
	\[\varphi u(X,t)=f(t).\]
\end{example}

\begin{example}
	Рассмотрим начально-краевую задачу на $[0,X]$ для волнового уравнения
	(уравнения акустики), которое уже было в примере
	\eqref{eq:wave_equation_example}:
	\[\begin{cases}
		u_t+v_x=0, \\
		v_t+a^2u_x=0. \\
	\end{cases}\]

	$a^2$ положим равным единице, тогда
	\[\boldsymbol{u}=
		\begin{pmatrix}
			u \\
			v \\
		\end{pmatrix},
	\qquad
	A=
		\begin{pmatrix}
			0 & 1 \\
			1 & 0 \\
		\end{pmatrix}.
	\]

	Собственные значения и собственные векторы матрицы $A$ равны
	\[\lambda_1=-1,\quad \lambda_2=1,\qquad
	\boldsymbol{l}_1=(1,-1),\quad \boldsymbol{l}_2=(1,1).\]

	На каждой границе будет по одному граничному условию. Для корректной
	поставновки граничных условий нужны векторы инвариантов. Они равны
	\[\omega_1=u-v,\qquad \omega_2=u+v.\]

	На левой границе $(\boldsymbol\varphi,\boldsymbol u)=f_1$, тогда
	\[
		\begin{cases}
			\varphi_1 u+\varphi_2 v=f_1, \\
			u-v=\omega_1. \\
		\end{cases}
	\]

	Применим условие корректности:
	\[
		\begin{vmatrix}
			\varphi_1 & \varphi_2 \\
			1	& -1	\\
		\end{vmatrix}
		\ne 0\Leftrightarrow
		\varphi_1\ne -\varphi_2.
	\]

	Аналогично на правой границе при $(\boldsymbol\varphi,\boldsymbol u)=
	f_2$
	\[
		\begin{cases}
			u+v=\omega_2, \\
			\varphi_1 u+\varphi_2 v=f_2. \\
		\end{cases}
		\Leftrightarrow\quad
		\begin{vmatrix}
			1	& 1	\\
			\varphi_1 & \varphi_2 \\
		\end{vmatrix}
		\ne 0\Leftrightarrow
		\varphi_1\ne \varphi_2.
	\]
\end{example}

\subsubsection{Разностные схемы, аппроксимирующие уравнения переноса}
Это любимая тема В. Остапенко. Рассматривать построение разностных схем
мы будем лишь для линейного уравнения переноса
\eqref{eq:convection-diffusion_equation}, однако правильность его решения лежит
в основе более сложных задач.

Несмотря на то что мы аппроксимируем функцию, вполне естественно требовать от
аппроксимации сохранения свойств точной функции, например, монотонности.

Здесь и далее будет использоваться обозначение $u_j^n=u(jh,n\tau)$, где $h$ --
шаг по координате, а $\tau$ -- шаг по времени. При этом значения $u^0_j$ при
некоторых $j$ являются начальными условиями.

\begin{define}\label{eq:two_layer_scheme}
	\textbf{Двуслойная по времени} разностная схема -- разностная схема вида
	\[u_j^{n+1}=\sum_{m\in M}C_mu_{j+m}^n.\]
\end{define}

\begin{define}
	Разностная схема \eqref{eq:two_layer_scheme} называется
	\textbf{монотонной}, если она при любом $j$ переводит монотонную функцию
	$u_j^n$ на следующий временной слой как функцию $u_j^{n+1}$, которая
	монотонна с тем же знаком (монотонно возрастающая функция не переходит в
	монотонно убывающую, и наоборот).
\end{define}

\begin{theorem}[критерий монотонности разностной схемы]
	Чтобы разностная схема \eqref{eq:two_layer_scheme} была монотонной,
	необходимо и достаточно, чтобы все коэффициенты $C_j$ были
	неотрицательные.
\end{theorem}

\begin{proof}
	Для определённости допустим, что $u_j^n$ -- монотонно возрастающая
	функция. Для монотонно убывающих функций доказательство аналогичное.
	
	\textbf{Необходимость}. Пусть все коэффициенты $C_j$ неотрицательные.
	Обозначим
	\[\Delta\circ u_j=u_j-u_{j-1}.\]
	Если схема монотонно возрастающая, то $u_{j+1}-u_j\ge 0$. Подействуем
	этим оператором на разностную схему. Благодаря его линейности,
	\[\Delta\circ u_j^{n+1}=\sum_{m\in M}C_m\Delta u_{j+m}^{n}\ge 0
	\Rightarrow u_j^{n+1}\text{ монотонно возрастающая}.\]

	\textbf{Достаточность}. Докажем от противного. Пусть $C_k<0$, а функция
	$u_j^n$ монотонно возрастающая. Здесь дана разность, направленная
	вперёд. Зададим $u_j^n$ так, что
	\[
		u_j^n=
		\begin{cases}
			0, & j < 0, \\
			1, & j\ge 0. \\
		\end{cases}
	\]
	Очевидно, что на данном временном слое функция монотонная и что
	\[\exists m\in M:j+m=0\Rightarrow
	\Delta u_j^n=C_{-j}\underset{1}{\underbrace{\Delta u_0^n}}.\]

	В том случае, если мы выберем $-j=k$, то получим, что
	$\Delta u_{-k}^n<0$, что является нарушением условия монотонности
	разностной схемы. Пришли к противоречию.
\end{proof}

\begin{define}\label{eq:CDE_forward_scheme}
	Простейщая разностная схема по потоку, аппроксимирующая линейное
	уравнение переноса, имеет вид
	\[\frac{u_j^{n+1}-u_j^n}{\tau}+a\frac{u_{j+1}^n-u_j^n}{h}=0.\]
\end{define}

\begin{define}\label{eq:CDE_backward_scheme}
	Простейщая разностная схема против потока, аппроксимирующая линейное
	уравнение переноса, имеет вид
	\[\frac{u_j^{n+1}-u_j^n}{\tau}+a\frac{u_j^n-u_{j-1}^n}{h}=0.\]
\end{define}

\begin{define}
	\textbf{Числом Куртанта} в разностной схеме линейного уравнения переноса
	называется число $\mathlarger{r=\frac{a\tau}{h}}$.
\end{define}

\begin{lemma}
	Разностная схема по потоку \eqref{eq:CDE_forward_scheme} не монотонна.
\end{lemma}

\begin{proof}\label{eq:CDE_forward_scheme_lemma}
	Запишем схему в явном виде:
	\[u_j^{n+1}=u_j^n-r(u_{j+1}^n-u_j^n).\]

	Найдём аппроксимацию сдвига функции
	\[v(x)=
		\begin{cases}
			0, & x<0, \\
			1, & x\ge 0. \\
		\end{cases}
	\]

	Схематично точное решение выглядит так, будто мы передвинули
	''ступеньку'':

	\subfile{graph-unit_step_function}

	Проверим, сохраняет ли разностная схема монотонность. Зададим нижний
	временной слой точно:
	\[u_j^0(x)=
		\begin{cases}
			0, & j<0, \\
			1, & j\ge 0. \\
		\end{cases}
	\]

	В отличие от $v(x)$, эта функция не непрерывная, а дискретная.

	Теперь зададим $u_j^1$, которая на следующем временном слое:
	\[u_j^1=u_j^0-r(u_{j+1}^0-u_j^0).\]

	Если посчитать все значения первого временного слоя, то получим, что
	\[u_j^1(x)=
		\begin{cases}
			0, & j<-1, \\
			-r,& j=-1, \\
			1, & j>-1, \\
		\end{cases}
	\]
	что сразу говорит о немонотонности первого временного слоя, так как
	$r>0$. Значит, разностная схема не монотонна.

	По критерию монотонности, мы имеем отрицательный коэффициент при
	$u_{j+1}^n$, что также говорит о немонотонности схемы.
\end{proof}

\begin{theorem}[условие устойчивости]
	Если число Куртанта $r\le 1$, то разностная схема против потока
	\eqref{eq:CDE_backward_scheme} монотонная.
\end{theorem}

\begin{proof}
	В явном виде схема имеет вид
	\[u_j^{n+1}=u_j^n-r(u_j^n-u_{j-1}^n).\]

	Проделаем те же шаги, что и в лемме \eqref{eq:CDE_forward_scheme_lemma},
	и получим, что на первом временном слое
	\[u_j^1(x)=
		\begin{cases}
			0,   & j<0, \\
			1-r, & j=0, \\
			1,   & j>0. \\
		\end{cases}
	\]

	Отсюда вытекает условие, при котором функция на данном временном слое
	останется монотонной: $r\le 1$. То же условие на число Куртанта можно
	получить и из критерия монотонной разностной схемы.
\end{proof}

\end{document}
